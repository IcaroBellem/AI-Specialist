from search import similarity_search
from sentence_transformers import SentenceTransformer

model = SentenceTransformer('paraphrase-MiniLM-L6-v2')

def calculate_embeddings(texts):
    embeddings = model.encode(texts)
    return embeddings

def chatbot_interaction(question, history, documents, embeddings, llm):
    basic_responses = {
        "bom dia": "Bom dia! Como posso ajudar voc√™ hoje?",
        "boa tarde": "Boa tarde! Como posso ajudar voc√™ hoje?",
        "boa noite": "Boa noite! Como posso ajudar voc√™ hoje?",
        "como voc√™ est√°?": "Estou bem, obrigado! Como posso ajudar voc√™ hoje?",
        "qual o seu nome?": "Eu sou o TechzAI, seu assistente virtual especializado em hardware e inform√°tica.",
        "o que voc√™ faz?": "Eu sou um assistente virtual especializado em responder perguntas sobre hardware e inform√°tica. Como posso ajudar voc√™ hoje?"
    }
    
    if question in basic_responses:
        return basic_responses[question]

    # Calcula os embeddings da pergunta e dos documentos
    question_embedding = calculate_embeddings([question])[0]
    document_embeddings = embeddings

    # Encontra os documentos mais similares
    top_k = 5  # n√∫mero de documentos mais similares a serem recuperados
    similar_docs_indices = similarity_search(question_embedding, document_embeddings, k=top_k)

    # Constr√≥i o contexto com os documentos mais similares encontrados
    context = " ".join([documents[idx] for idx in similar_docs_indices])
    
    history_text = "\n".join([f"Usu√°rio: {msg['content']}" if msg['role'] == 'user' else f"Assistente: {msg['content']}" for msg in history])

    if context.strip():
        prompt = f"Voc√™ √© um especialista em inform√°tica e hardware e programa√ß√£o simp√°tico e est√° respondendo a pergunta de um usu√°rio. O usu√°rio pergunta: {question}. Responda a pergunta do usu√°rio de forma amig√°vel e informativa utilizando o contexto: {context}. **Caso n√£o saiba a resposta, diga que n√£o sabe.** üòä\n\nHist√≥rico:\n{history_text}\n\nNova pergunta: {question}. Lembre-se que voc√™ √© um especialista em inform√°tica e hardware simp√°tico, ou seja, voc√™ n√£o sabe coisas al√©m da sua especialidade. Por√©m, se a informa√ß√£o estiver na sua base de dados fornecida, responda ao usu√°rio com a sua base de dados.\n\n"
    else:
        prompt = f"Voc√™ √© um assistente especializado em inform√°tica e hardware e programa√ß√£o. Responda a pergunta do usu√°rio da melhor forma poss√≠vel, mas n√£o d√™ respostas longas. Pergunta: {question}\n\nHist√≥rico:\n{history_text}\n\nNova pergunta: {question}. Lembre-se que voc√™ √© um especialista em inform√°tica e hardware simp√°tico, ou seja, voc√™ n√£o sabe coisas al√©m da sua especialidade. Mesmo se uma nova conversa for iniciada, se a informa√ß√£o estiver na sua base de dados fornecida, responda ao usu√°rio com a sua base dados.\n\n"
    
    try:
        response = llm.invoke(prompt)
        return response.content
    except Exception as e:
        return f"Desculpe, n√£o consegui entender sua pergunta. Erro: {e}"
